apiVersion: "kubeflow.org/v1beta1"
kind: Experiment
metadata:
  namespace: kubeflow-user-example-com # namespace
  name: demo # experiment name

# Experiment 관련 메타 정보 작성
spec:
  # Objective Function
  # 최적화하기 위한 metric, type, early stopping goal 등을 포함
  objective:
    type: maximize
    goal: 0.99
    
    # Trial 에서 출력할 때, 정해진 형식으로 StdOut 으로 출력하면 name 을 parsing 할 수 있음
    # https://www.kubeflow.org/docs/components/katib/experiment/#metrics-collector

    # objectiveMetricName 은 hp search 를 수행할 objective metric 의 이름
    # addtionalMetricName 은 hp search 와는 관계없지만 함께 출력할 metric 의 이름
    objectiveMetricName: Validation-accuracy
    additionalMetricNames:
      - Train-accuracy

  # Hyperparameter Search Algorithm
  algorithm:
    # Katib 에서는 현재 지원하고 있는 search algorithm 이 다음과 같이 정해져 있습니다.
    # https://www.kubeflow.org/docs/components/katib/experiment/#search-algorithms

    # 각각의 algorithm 은 정해진 HP search package 를 사용하여 동작하며,
    # 어떤 docker image 를 사용할 것인지는 katib 설치 당시 배포한 configmap 에 적혀있습니다.
    # 다음 명령을 통해서 어떤 algorithm 이 어떤 package 를 사용하는지 확인할 수 있습니다.
    # `kubectl get configmap katib-config -o yaml` 의 suggestion 필드 확인
    algorithmName: random

  # 병렬로 실행할 Trial 의 개수
  parallelTrialCount: 1

  # 최대 Trial 개수 (도달하면 실험 종료 : Succeeded status 로 종료)
  maxTrialCount: 1

  # 최대 failed Trial 개수 (도달하면 실험 종료 : Failed status 로 종료)
  maxFailedTrialCount: 1 

  # HP Search 를 수행할 space 정의
  # 각각의 hyperparameter 마다 type 은 무엇인지, space 는 무엇인지를 정의
  # https://github.com/kubeflow/katib/blob/195db292374dcf3b39b55dcb3fcd14b3a55d5942/pkg/apis/controller/experiments/v1beta1/experiment_types.go#L186-L207
  parameters:
    - name: lr # 뒤의 필드 중 trialTemplate.trialParameters[x].reference 와 일치해야 합니다. (실수하기 쉬운 부분)
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.03"
    - name: num-layers
      parameterType: int
      feasibleSpace:
        min: "2"
        max: "5"
    - name: optimizer
      parameterType: categorical
      feasibleSpace:
        list:
          - sgd
          - adam
          - ftrl

  # Suggestion 에 의해 생성된 HP 후보 조합 하나를 input 으로 받아서 학습 및 평가를 진행할 Trial 의 템플릿
  trialTemplate:

    # 아래 trialSpec.spec.template.spec.containers[x].name 중에서 metric 을 출력하는 container 의 이름
    # 지금 예시에서는 container 가 하나뿐이므로 해당 container 의 이름으로 출력
    primaryContainerName: training-container

    # 아래 trialSpec.spec.template.spec.containers[x].command (or args) 에서 사용할 Hyperparameter 에 대한 메타 정보 정의
    # trialParameters[x].name 은 아래 trialSpec 에서의 값과 매핑되며,
    # trialParameters[x].reference 는 위의 parameters[x].name 과 매핑됩니다.
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: numberLayers
        description: Number of training model layers
        reference: num-layers
      - name: optimizer
        description: Training model optimizer (sdg, adam or ftrl)
        reference: optimizer

    # trialSpec 으로는 Job, TfJob 등의 리소스를 사용할 수 있으며, 본 예시는 Job 을 사용합니다.
    # https://www.kubeflow.org/docs/components/katib/trial-template/
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          # 현재 버전의 katib 는 istio sidecar 와 함께 사용할 수 없습니다.
          # 자세한 내용은 다음 페이지를 확인하시기 바랍니다.
          # https://www.kubeflow.org/docs/components/katib/hyperparameter/#example-using-random-search-algorithm
          # https://github.com/kubeflow/katib/issues/1638
          metadata:
            annotations:
              sidecar.istio.io/inject: "false"
          spec:
            containers:
              - name: training-container

                # 해당 이미지는 미리 docker build and push 되어있어야 사용 가능
                # 해당 docker image 를 빌드한 Dockerfile 및 소스코드는 다음 경로에서 확인
                # https://github.com/kubeflow/katib/tree/983a867/examples/v1beta1/trial-images/mxnet-mnist
                image: docker.io/kubeflowkatib/mxnet-mnist:v1beta1-45c5727 
                command:
                  - "python3"
                  - "/opt/mxnet-mnist/mnist.py"
                  - "--batch-size=64"
                  - "--lr=${trialParameters.learningRate}"
                  - "--num-layers=${trialParameters.numberLayers}"
                  - "--optimizer=${trialParameters.optimizer}"
                  - "--num-epochs=1" # 테스트 시 시간 소요를 줄이기 위해 epoch 은 1 회만 수행하겠습니다.
            restartPolicy: Never
